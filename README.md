# 🧠 Basic-llm-chatbot

A lightweight local LLM chatbot setup, perfect for personal use and experimentation. Built using Python, Flask, and Ollama, with local model serving via LM Studio. Ideal for developers who want a simple, fast, and private chatbot interface.

---

## 🛠 Technologies

- 🐍 **Python 3.10.11** ([Download](https://www.python.org/downloads/release/python-3100/))
- 🔹 **Flask** (Micro web framework)
- 🤖 **Ollama** ([Website](https://ollama.com/))
- 🧪 **LM Studio** ([Website](https://lmstudio.ai/))
- 💻 **VS Code** (or any IDE you prefer) ([Download](https://code.visualstudio.com/))

---

## 🚀 Features

- 🧠 Local LLM chatbot with no external dependencies
- 🔒 Private, lightweight, and customizable
- 🧰 Flask-powered web interface
- ⚙️ Easy setup with virtual environment
- 🧪 Test models easily via LM Studio

---

## ⚙️ Setup Instructions

```bash
# Step 1: Install Python 3.10.x
Download from: https://www.python.org/downloads/release/python-3100/

# Step 2: Create a virtual environment
python -m venv venv

# Step 3: Activate the virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# Step 4: Install Flask
pip install flask

# Step 5: Install and run Ollama
Visit: https://ollama.com/

# Step 6: Download and test models via LM Studio
Visit: https://lmstudio.ai/
```

---

## ✅ Verifying Installation

Make sure everything is working:

```bash
python --version
# Output should be: Python 3.10.11

flask --version
# Output should confirm Flask is installed

ollama --version
# Output confirms Ollama is installed
```

---

## 💡 Notes

- You can use any IDE, but **VS Code** is recommended for convenience.
- Ensure Ollama and LM Studio are not running on the same port if used together.
- Great for building personal projects and experimenting with local LLMs.

---

## 🧠 Author

Made with ❤️ by **Pranziss**
