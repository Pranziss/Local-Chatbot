# ğŸ§  Basic-llm-chatbot

A lightweight local LLM chatbot setup, perfect for personal use and experimentation. Built using Python, Flask, and Ollama, with local model serving via LM Studio. Ideal for developers who want a simple, fast, and private chatbot interface.

---

## ğŸ›  Technologies

- ğŸ **Python 3.10.11** ([Download](https://www.python.org/downloads/release/python-3100/))
- ğŸ”¹ **Flask** (Micro web framework)
- ğŸ¤– **Ollama** ([Website](https://ollama.com/))
- ğŸ§ª **LM Studio** ([Website](https://lmstudio.ai/))
- ğŸ’» **VS Code** (or any IDE you prefer) ([Download](https://code.visualstudio.com/))

---

## ğŸš€ Features

- ğŸ§  Local LLM chatbot with no external dependencies
- ğŸ”’ Private, lightweight, and customizable
- ğŸ§° Flask-powered web interface
- âš™ï¸ Easy setup with virtual environment
- ğŸ§ª Test models easily via LM Studio

---

## âš™ï¸ Setup Instructions

```bash
# Step 1: Install Python 3.10.x
Download from: https://www.python.org/downloads/release/python-3100/

# Step 2: Create a virtual environment
python -m venv venv

# Step 3: Activate the virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# Step 4: Install Flask
pip install flask

# Step 5: Install and run Ollama
Visit: https://ollama.com/

# Step 6: Download and test models via LM Studio
Visit: https://lmstudio.ai/
```

---

## âœ… Verifying Installation

Make sure everything is working:

```bash
python --version
# Output should be: Python 3.10.11

flask --version
# Output should confirm Flask is installed

ollama --version
# Output confirms Ollama is installed
```

---

## ğŸ’¡ Notes

- You can use any IDE, but **VS Code** is recommended for convenience.
- Ensure Ollama and LM Studio are not running on the same port if used together.
- Great for building personal projects and experimenting with local LLMs.

---

## ğŸ§  Author

Made with â¤ï¸ by **Pranziss**
